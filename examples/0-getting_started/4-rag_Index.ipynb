{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d13ba9-8054-4c0b-82bb-d60784e7974a",
   "metadata": {},
   "source": [
    "构建RAG的第一步是构建私域数据的索引，以便后续提取到相关上下文。构建索引一般分为以下三个步骤：\n",
    "\n",
    "![alt text](../../doc/image.png)\n",
    "\n",
    "- **加载数据**：从不同的数据源加载数据，如txt、pdf、excle、sql等\n",
    "- **转换数据**：加载上来的数据不直接存储，需要分块、提取元数据等操作\n",
    "- **索引及存储数据**：构建分块的索引，存储到向量库中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35294eba-46e3-424b-a396-8fa9b510d8dc",
   "metadata": {},
   "source": [
    "## 加载数据\n",
    "\n",
    "加载数据是为了从Markdown、PDF、Word 文档、PowerPoint 幻灯片、图像、音频和视频等不同数据源提取数据，并将其用于初始化Document对象\n",
    "\n",
    "最简单的加载器是SimpleDirectoryReader，从指定目录加载Markdown、PDF、Word 文档、PowerPoint 幻灯片、图像、音频和视频等数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e592e3-0ea1-49d9-acfb-b604403a86fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T03:50:58.043974Z",
     "iopub.status.busy": "2024-12-04T03:50:58.042973Z",
     "iopub.status.idle": "2024-12-04T03:51:01.333660Z",
     "shell.execute_reply": "2024-12-04T03:51:01.332663Z",
     "shell.execute_reply.started": "2024-12-04T03:50:58.043974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████████| 42/42 [00:00<00:00, 44.97file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\\三国演义白话文\",recursive=True).load_data(show_progress=True)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2b724-ab60-4d5a-b9d4-a31ceac8819b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T00:51:00.706436Z",
     "iopub.status.busy": "2024-12-04T00:51:00.705437Z",
     "iopub.status.idle": "2024-12-04T00:51:00.725878Z",
     "shell.execute_reply": "2024-12-04T00:51:00.723433Z",
     "shell.execute_reply.started": "2024-12-04T00:51:00.705437Z"
    }
   },
   "source": [
    "除此之外，我们可以使用更加低级的接口，直接将文本加载为Document对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07832a39-90c7-4c4a-8171-c9b770b42015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T00:52:28.221938Z",
     "iopub.status.busy": "2024-12-04T00:52:28.221938Z",
     "iopub.status.idle": "2024-12-04T00:52:28.234004Z",
     "shell.execute_reply": "2024-12-04T00:52:28.231950Z",
     "shell.execute_reply.started": "2024-12-04T00:52:28.221938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='dfb3fd37-f8a6-4203-96a4-9509b28537ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='123456', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), Document(id_='75fec794-dabd-47ca-b232-47954c153b41', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='abcdef', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc1=Document(text=\"123456\")\n",
    "doc2=Document(text=\"abcdef\")\n",
    "\n",
    "documents=[doc1,doc2]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870cd5b-af24-42da-9ba7-f73322c470c1",
   "metadata": {},
   "source": [
    "除了以上LlamaIndex直接提供的接口外，在[Llama Hub](https://llamahub.ai/?tab=readers) 提供针对不同数据源的加载方式，还提供将这些加载对象转为其他框架的接口，以下是针对网页的加载器示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e65425f-6d57-46c2-ba9f-55619a550229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:05:36.316759Z",
     "iopub.status.busy": "2024-12-04T01:05:36.315757Z",
     "iopub.status.idle": "2024-12-04T01:06:20.900441Z",
     "shell.execute_reply": "2024-12-04T01:06:20.898913Z",
     "shell.execute_reply.started": "2024-12-04T01:05:36.316759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>LlamaIndex 加载数据主要有以下几种方式：\n",
       "\n",
       "1. **使用 `SimpleDirectoryReader` 载入简单目录中的文件**：\n",
       "   ```python\n",
       "   from llama_index.core import SimpleDirectoryReader\n",
       "   \n",
       "   documents = SimpleDirectoryReader(\"./data\").load_data()\n",
       "   ```\n",
       "\n",
       "2. **利用读取器从 LlamaHub 加载数据**：\n",
       "   例如，使用 `DatabaseReader` 从 SQL 数据库加载数据。\n",
       "   ```python\n",
       "   from llama_index.core import download_loader\n",
       "   \n",
       "   from llama_index.readers.database import DatabaseReader\n",
       "   \n",
       "   reader = DatabaseReader(\n",
       "       scheme=os.getenv(\"DB_SCHEME\"),\n",
       "       host=os.getenv(\"DB_HOST\"),\n",
       "       port=os.getenv(\"DB_PORT\"),\n",
       "       user=os.getenv(\"DB_USER\"),\n",
       "       password=os.getenv(\"DB_PASS\"),\n",
       "       dbname=os.getenv(\"DB_NAME\"),\n",
       "   )\n",
       "   \n",
       "   query = \"SELECT * FROM users\"\n",
       "   documents = reader.load_data(query=query)\n",
       "   ```\n",
       "\n",
       "3. **直接创建文档**：\n",
       "   ```python\n",
       "   from llama_index.core import Document\n",
       "   \n",
       "   doc = Document(text=\"text\")\n",
       "   ```\n",
       "\n",
       "这些方法提供了灵活的数据加载选项，可以根据具体需求选择合适的方式来处理和加载数据。</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 默认不带这个加载器，通过命令安装：python -m pip install llama-index-readers-web\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "# 从网页加载数据\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://docs.llamaindex.ai/en/stable/understanding/loading/loading/\"]\n",
    ")\n",
    "print(len(documents))\n",
    "\n",
    "# 加载模型 \n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "Settings.llm = Ollama(model=\"qwen2.5:latest\", request_timeout=360.0,base_url='http://192.168.3.155:11434')\n",
    "\n",
    "# 创建摘要索引\n",
    "from llama_index.core import SummaryIndex\n",
    "from IPython.display import Markdown, display\n",
    "index = SummaryIndex.from_documents(documents)\n",
    "\n",
    "# 创建查询引擎并查询内容\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"LlamaIndex加载数据有几种方式？\")\n",
    "\n",
    "# 显示查询结果\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad929723-6c87-410d-b419-e6cdde2cf94a",
   "metadata": {},
   "source": [
    "## 转换\n",
    "\n",
    "转换的目的是将documents内的所有文档进行分块、提取元数据操作，在代码层面，就是将documents转为分块的nodes\n",
    "\n",
    "以下代码通过自定义文本分割器，实现文本切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86c873c-153d-407b-ab9c-366226cd110a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:29:43.157838Z",
     "iopub.status.busy": "2024-12-04T01:29:43.155838Z",
     "iopub.status.idle": "2024-12-04T01:29:43.812606Z",
     "shell.execute_reply": "2024-12-04T01:29:43.810610Z",
     "shell.execute_reply.started": "2024-12-04T01:29:43.156840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading files: 100%|████████████| 41/41 [00:00<00:00, 1320.46file/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "258 \n",
      " Node ID: 371f3091-6281-4e0f-a771-04ca7368afe4\n",
      "Text: 第一回 桃园结义     　　东汉末年，朝政腐败，再加上连年灾荒，老百姓的日子非常困苦。巨鹿人张角见人民怨恨官府，便与他的弟弟张\n",
      "梁、张宝在河北、河南、山东、湖北、江苏等地，招收了五十万人，举行起义，一起向官兵进攻。 　　没有几天，四方百姓，头裹黄巾，跟随张角三兄弟杀向\n",
      "官府，声势非常浩大。汉灵帝得到各地报告，连忙下令各地官军防备。又派中郎将卢植、皇甫嵩、朱隽率领一精一兵，分路攻打张角兄弟的黄巾军。\n",
      "　　张角领军攻打幽州地界，幽州太守连忙召校尉邹靖商议，邹靖说幽州兵少不能抵挡。建议写榜文到各县招募兵马。\n",
      "　　榜文行到涿县，引出一名英雄，这人姓刘名备，字玄德。因家里贫寒，靠贩麻鞋、织草席为生。这天他进城来看榜文。\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\\三国演义白话文\",recursive=True).load_data(show_progress=True)\n",
    "print(len(documents))\n",
    "\n",
    "pipeline=IngestionPipeline(transformations=[\n",
    "    TokenTextSplitter(chunk_size=500,chunk_overlap=100)])\n",
    "\n",
    "nodes=pipeline.run(documents=documents)\n",
    "print(len(nodes),'\\n',nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b0cdf-3695-4cbc-b0db-bc52277f939b",
   "metadata": {},
   "source": [
    "## 索引及存储\n",
    "\n",
    "索引是通过embedding模型，得到文档nodes的嵌入向量，然后存储到向量数据库中，所以这步的目的是创建向量数据库\n",
    "\n",
    "基于转换后的文档nodes，可以直接创建向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eab3b7d-4060-4197-8df9-7af0c52c39c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:29:56.450518Z",
     "iopub.status.busy": "2024-12-04T01:29:56.449516Z",
     "iopub.status.idle": "2024-12-04T01:30:47.813251Z",
     "shell.execute_reply": "2024-12-04T01:30:47.811932Z",
     "shell.execute_reply.started": "2024-12-04T01:29:56.450518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edbf2b9802049438fef93605412c888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x000002768F0B77F0>\n"
     ]
    }
   ],
   "source": [
    "# 设置embedding model \n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import Settings\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"quentinz/bge-large-zh-v1.5:latest\",base_url='http://192.168.3.155:11434')\n",
    "\n",
    "# 构建向量数据库 \n",
    "from llama_index.core import VectorStoreIndex\n",
    "index=VectorStoreIndex(nodes=nodes,show_progress=True)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9c3fb-99bd-4808-883a-dd180e8e9aba",
   "metadata": {},
   "source": [
    "如果不需要定制转换方式，可以用以下接口快速从documents生成向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc172d0b-b8ac-4ce2-aefd-8a4b51583707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:37:13.882359Z",
     "iopub.status.busy": "2024-12-04T01:37:13.881359Z",
     "iopub.status.idle": "2024-12-04T01:39:32.570440Z",
     "shell.execute_reply": "2024-12-04T01:39:32.568923Z",
     "shell.execute_reply.started": "2024-12-04T01:37:13.882359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8508566fff04d0ea068c273be8210de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ce563d1b6244bbb9f90d11256d5a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index=VectorStoreIndex.from_documents(documents=documents,show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f6c1c2-e251-4bad-9544-56fac29dc453",
   "metadata": {},
   "source": [
    "如果需要定制转换过程时，可以通过以下方式进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2b31db4-0ce2-4d81-b5b5-af38f6734910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:40:43.909586Z",
     "iopub.status.busy": "2024-12-04T01:40:43.908590Z",
     "iopub.status.idle": "2024-12-04T01:41:46.268624Z",
     "shell.execute_reply": "2024-12-04T01:41:46.266603Z",
     "shell.execute_reply.started": "2024-12-04T01:40:43.909586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65845395998d423f81cb1046a9969feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112258cc74b946a1ae2e4f3148d1d4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "\n",
    "# global\n",
    "from llama_index.core import Settings\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "# per-index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[text_splitter],show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649c275-b4c8-4c31-b264-dc3305716141",
   "metadata": {},
   "source": [
    "也有更加低级的接口，如果已知每个chunk的文本，可以直接定义文档的node对象，然后初始化向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3afce2-1a21-463e-932d-32ef7744cfe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T01:42:45.563377Z",
     "iopub.status.busy": "2024-12-04T01:42:45.562376Z",
     "iopub.status.idle": "2024-12-04T01:42:47.847455Z",
     "shell.execute_reply": "2024-12-04T01:42:47.845075Z",
     "shell.execute_reply.started": "2024-12-04T01:42:45.563377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7030cc0591e74786b4c548b73bf3431d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "node1 = TextNode(text=\"abc\", id_=\"100\")\n",
    "node2 = TextNode(text=\"123\", id_=\"200\")\n",
    "\n",
    "index = VectorStoreIndex([node1, node2],show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f7f01-5c2b-4672-b1e9-d4fed5aff542",
   "metadata": {},
   "source": [
    "完成向量数据库的构建后，下一步可以将向量数据库持久化到磁盘，下次直接加载使用即可，而不必要重新构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b38a887f-958f-41e5-a455-04a7a7251a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T02:03:52.890200Z",
     "iopub.status.busy": "2024-12-04T02:03:52.889199Z",
     "iopub.status.idle": "2024-12-04T02:03:53.010216Z",
     "shell.execute_reply": "2024-12-04T02:03:53.008735Z",
     "shell.execute_reply.started": "2024-12-04T02:03:52.890200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量数据库持久化 \n",
    "persist_dir='./vector_storage'\n",
    "index.storage_context.persist(persist_dir=persist_dir)\n",
    "\n",
    "# 加载持久化的向量数据库\n",
    "from llama_index.core import StorageContext,load_index_from_storage\n",
    "storage_context=StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "index=load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a2607-6854-4254-963c-7611fb041022",
   "metadata": {},
   "source": [
    "代码中的storage_context指的是不同的向量数据库，所谓不同，是指向量数据库存储机制、检索机制不同，如有的向量数据库擅长存储关系型数据，有的向量数据库可以进行更加复杂的检索方式。LlamaIndex支持多种向量数据库，比如chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a2621b-a31c-4deb-b7f8-c22e2a1bfdb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T02:11:11.001343Z",
     "iopub.status.busy": "2024-12-04T02:11:11.001343Z",
     "iopub.status.idle": "2024-12-04T02:12:53.172345Z",
     "shell.execute_reply": "2024-12-04T02:12:53.169339Z",
     "shell.execute_reply.started": "2024-12-04T02:11:11.001343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|█████████████| 41/41 [00:00<00:00, 694.39file/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c4d5cc95b4424b9261b18fcb0dee9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b01bf6e0874f23ba1d3b7b85b36e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在长坂坡，张飞独立桥上，身后尘土飞扬。曹操怀疑这是诸葛亮的计策，不敢轻易靠近。张飞一声大喝，吓得曹军兵马人仰马翻而退。随后，他拆断了桥梁，并前去见刘备，报告了这一情况。\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "# 需要先pip install llama-index-vector-stores-chroma \n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\\三国演义白话文\",recursive=True).load_data(show_progress=True)\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# create your index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context,show_progress=True\n",
    ")\n",
    "\n",
    "# create a query engine and query\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"张飞长坂坡做了什么事？\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
