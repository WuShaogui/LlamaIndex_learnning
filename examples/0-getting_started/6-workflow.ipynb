{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本脚本展示了如何使用 llama_index 库中的工作流（Workflow）系统来构建和运行复杂的流程管理逻辑。通过定义不同的事件类型、步骤函数以及上下文对象，可以实现从简单的线性流程到并发执行、事件收集、嵌套工作流等多种复杂的工作流模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顺序工作流\n",
    "\n",
    "工作流通过继承Workflow类实现，这个类包含几个步骤，并且每个步骤使用装饰器@step装饰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "\n",
    "class MyWorkflow(Workflow):\n",
    "\n",
    "    @step\n",
    "    async def my_step(self,ev:StartEvent)->StopEvent:\n",
    "        return StopEvent(result=\"hello world\")\n",
    "\n",
    "w=MyWorkflow(timeout=10,verbose=False)\n",
    "result=await w.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上工作流定义了开头步骤（StartEvent）和结束标志（StopEvent），这很重要\n",
    "\n",
    "llamaIndex通过以下代码将工作流可视化，可视化内容存在html，使用浏览器打开即可\n",
    "\n",
    "![](../../../../../c:/CodeRepos/python/MyCode/LlamaIndex_learnning/doc/2024-12-19_105411.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "basic_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(MyWorkflow, filename=\"basic_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步地，我们通过定义不同的Event，构建多级的工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the workflow.\n",
      "First step complete.\n",
      "Second step complete.\n",
      "Workflow complete.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "\n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "\n",
    "# 定义工作流\n",
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ev: StartEvent) -> FirstEvent:\n",
    "        print(ev.first_input)\n",
    "        return FirstEvent(first_output=\"First step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ev: FirstEvent) -> SecondEvent:\n",
    "        print(ev.first_output)\n",
    "        return SecondEvent(second_output=\"Second step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ev: SecondEvent) -> StopEvent:\n",
    "        print(ev.second_output)\n",
    "        return StopEvent(result=\"Workflow complete.\")\n",
    "\n",
    "\n",
    "w = MyWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run(first_input=\"Start the workflow.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结** ：\n",
    "\n",
    "- WorkFLow是一个起点为StartEvent，终点为StopEvent的流程\n",
    "- 通过定义不同的Event，构建其多级的工作流\n",
    "- 工作流内支持变量的流转"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分支循环工作流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上例子，只展示了顺序执行的工作流，对于复杂的分支、循环工作流如何构建呢？还是一样，首先定义监听事件Event，通过不同的指定方式来构建不同的工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad thing happened\n",
      "Bad thing happened\n",
      "Bad thing happened\n",
      "Good thing happened\n",
      "First step complete.\n",
      "Second step complete.\n",
      "Workflow complete.\n",
      "<class 'NoneType'>\n",
      "<class '__main__.FirstEvent'>\n",
      "<class '__main__.LoopEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.SecondEvent'>\n",
      "loop_workflow.html\n"
     ]
    }
   ],
   "source": [
    "# 循环工作流\n",
    "class LoopEvent(Event):\n",
    "    loop_output: str\n",
    "\n",
    "# 定义工作流\n",
    "import random\n",
    "class LoopWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ev: StartEvent | LoopEvent) -> FirstEvent | LoopEvent:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"Bad thing happened\")\n",
    "            return LoopEvent(loop_output=\"Back to step one.\")\n",
    "        else:\n",
    "            print(\"Good thing happened\")\n",
    "            return FirstEvent(first_output=\"First step complete.\")\n",
    "        \n",
    "    @step\n",
    "    async def step_two(self, ev: FirstEvent) -> SecondEvent:\n",
    "        print(ev.first_output)\n",
    "        return SecondEvent(second_output=\"Second step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ev: SecondEvent) -> StopEvent:\n",
    "        print(ev.second_output)\n",
    "        return StopEvent(result=\"Workflow complete.\")\n",
    "    \n",
    "w = LoopWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print(result)\n",
    "\n",
    "draw_all_possible_flows(LoopWorkflow, filename=\"loop_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多次运行代码，可以发现代码工作流流程有两种：\n",
    "\n",
    "- A: one[FirstEvent]->two[SecondEvent]-three[StopEvent]\n",
    "- B: 随机次数one[LoopEvent]-> A\n",
    "\n",
    "也就是说：**下一步执行那个动作，取决于当前返回事件和动作的监听事件，比如动作two监听FirstEvent，只要当前返回事件是FirstEvent，下一步就会执行two，这一点和MetaGPT定义WorkFlow的概念类似**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to branch A\n",
      "Branch A\n",
      "Branch A\n",
      "Branch A complete.\n",
      "<class 'NoneType'>\n",
      "<class '__main__.BranchA1Event'>\n",
      "<class '__main__.BranchB1Event'>\n",
      "<class '__main__.BranchA2Event'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.BranchB2Event'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "branch_workflow.html\n"
     ]
    }
   ],
   "source": [
    "# 分支工作流\n",
    "class BranchA1Event(Event):\n",
    "    payload: str\n",
    "\n",
    "\n",
    "class BranchA2Event(Event):\n",
    "    payload: str\n",
    "\n",
    "\n",
    "class BranchB1Event(Event):\n",
    "    payload: str\n",
    "\n",
    "\n",
    "class BranchB2Event(Event):\n",
    "    payload: str\n",
    "\n",
    "\n",
    "class BranchWorkflow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ev: StartEvent) -> BranchA1Event | BranchB1Event:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"Go to branch A\")\n",
    "            return BranchA1Event(payload=\"Branch A\")\n",
    "        else:\n",
    "            print(\"Go to branch B\")\n",
    "            return BranchB1Event(payload=\"Branch B\")\n",
    "\n",
    "    @step\n",
    "    async def step_a1(self, ev: BranchA1Event) -> BranchA2Event:\n",
    "        print(ev.payload)\n",
    "        return BranchA2Event(payload=ev.payload)\n",
    "\n",
    "    @step\n",
    "    async def step_b1(self, ev: BranchB1Event) -> BranchB2Event:\n",
    "        print(ev.payload)\n",
    "        return BranchB2Event(payload=ev.payload)\n",
    "\n",
    "    @step\n",
    "    async def step_a2(self, ev: BranchA2Event) -> StopEvent:\n",
    "        print(ev.payload)\n",
    "        return StopEvent(result=\"Branch A complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_b2(self, ev: BranchB2Event) -> StopEvent:\n",
    "        print(ev.payload)\n",
    "        return StopEvent(result=\"Branch B complete.\")\n",
    "\n",
    "w = BranchWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print(result)\n",
    "\n",
    "draw_all_possible_flows(BranchWorkflow, filename=\"branch_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工作流上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在以上例子中，可以看见变量状态随着流程进行传递，如果要在未直接连接的步骤之间传递数据，则需要通过两者之间的所有步骤传递数据。这会使您的代码更难阅读和维护\n",
    "\n",
    "为了解决这个问题，为工作流引入一个全局可用的对象Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to load data\n",
      "Data is  [1, 2, 3]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "\n",
    "class SetupEvent(Event):\n",
    "    query: str\n",
    "\n",
    "\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "\n",
    "class StatefulFlow(Workflow):\n",
    "    @step\n",
    "    async def start(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> SetupEvent | StepTwoEvent:\n",
    "        db = await ctx.get(\"some_database\", default=None)\n",
    "        if db is None:\n",
    "            print(\"Need to load data\")\n",
    "            return SetupEvent(query=ev.query)\n",
    "\n",
    "        # do something with the query\n",
    "        return StepTwoEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def setup(self, ctx: Context, ev: SetupEvent) -> StartEvent:\n",
    "        # load data\n",
    "        await ctx.set(\"some_database\", [1, 2, 3])\n",
    "        return StartEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:\n",
    "        # do something with the data\n",
    "        print(\"Data is \", await ctx.get(\"some_database\"))\n",
    "\n",
    "        return StopEvent(result=await ctx.get(\"some_database\"))\n",
    "\n",
    "w = StatefulFlow(timeout=10, verbose=False)\n",
    "result = await w.run(query=\"Some query\")\n",
    "print(result)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流式处理事件\n",
    "\n",
    "llamaIndex中的WorkFlow的Context支持传递事件，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "import asyncio\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "\n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "    response: str\n",
    "\n",
    "class ProgressEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ctx: Context, ev: StartEvent) -> FirstEvent:\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=\"Step one is happening\"))\n",
    "        return FirstEvent(first_output=\"First step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: FirstEvent) -> SecondEvent:\n",
    "        llm  = Ollama(\n",
    "            model=\"qwen2.5:latest\", \n",
    "            request_timeout=360.0,\n",
    "            base_url='http://localhost:11434')\n",
    "        \n",
    "        generator = await llm.astream_complete(\n",
    "            \"用中文给我讲2个笑话，每个笑话不超过15个字\"\n",
    "        )\n",
    "        async for response in generator:\n",
    "            # Allow the workflow to stream this piece of response\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=response.delta))\n",
    "        return SecondEvent(\n",
    "            second_output=\"Second step complete, full response attached\",\n",
    "            response=str(response),\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, ev: SecondEvent) -> StopEvent:\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=\"Step three is happening\"))\n",
    "        return StopEvent(result=\"Workflow complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step step_one\n",
      "Step step_one produced event FirstEvent\n",
      "Running step step_two\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step one is happening\n",
      "1\n",
      ".\n",
      " 老\n",
      "婆\n",
      "做饭\n",
      "咸\n",
      "，\n",
      "加\n",
      "点\n",
      "水\n",
      "稀\n",
      "释\n",
      "一下\n",
      "。\n",
      "\n",
      "2\n",
      ".\n",
      " \n",
      " why\n",
      " did\n",
      " the\n",
      " tomato\n",
      " turn\n",
      " red\n",
      "?\n",
      " Because\n",
      " it\n",
      " saw\n",
      " the\n",
      " salad\n",
      " dressing\n",
      "!\n",
      "\n",
      "Step step_two produced event SecondEvent\n",
      "Running step step_three\n",
      "Step step_three produced event StopEvent\n",
      "Step three is happening\n",
      "Final result Workflow complete.\n",
      "<class 'NoneType'>\n",
      "<class '__main__.FirstEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.SecondEvent'>\n",
      "streaming_workflow.html\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    w = MyWorkflow(timeout=30, verbose=True)\n",
    "    handler = w.run(first_input=\"Start the workflow.\")\n",
    "\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ProgressEvent):\n",
    "            print(ev.msg)\n",
    "\n",
    "    final_result = await handler\n",
    "    print(\"Final result\", final_result)\n",
    "\n",
    "    draw_all_possible_flows(MyWorkflow, filename=\"streaming_workflow.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工作流的并发执行\n",
    "\n",
    "llamaindex的工作流可以被并发执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#  一次性发出多个事件\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class ParallelFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 3\"))\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:\n",
    "        print(\"Running slow query \", ev.query)\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "\n",
    "        return StopEvent(result=ev.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "Running slow query  Query 1\n",
      "Running step step_two\n",
      "Running slow query  Query 2\n",
      "Running step step_two\n",
      "Running slow query  Query 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step step_two produced event StopEvent\n",
      "<class 'NoneType'>\n",
      "<class '__main__.StepTwoEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "parallel_workflow.html\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    w = ParallelFlow(timeout=30, verbose=True)\n",
    "    await  w.run()\n",
    "\n",
    "    draw_all_possible_flows(ParallelFlow, filename=\"parallel_workflow.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上流程，step_two每次接受一个结果就执行，这在某些情况下适合，在某些情况下需要等待所有调用完成再执行，此时通过collect_events来判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "Running query  Query 1\n",
      "Running step step_two\n",
      "Running query  Query 2\n",
      "Running step step_two\n",
      "Running query  Query 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step step_two produced event StepThreeEvent\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "result: [StepThreeEvent(result='Query 1'), StepThreeEvent(result='Query 2'), StepThreeEvent(result='Query 3')]\n",
      "Step step_three produced event StopEvent\n",
      "<class 'NoneType'>\n",
      "<class '__main__.StepTwoEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.StepThreeEvent'>\n",
      "concurrent_workflow.html\n"
     ]
    }
   ],
   "source": [
    "class StepThreeEvent(Event):\n",
    "    result: str\n",
    "\n",
    "class ConcurrentFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 3\"))\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StepThreeEvent:\n",
    "        print(\"Running query \", ev.query)\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "        return StepThreeEvent(result=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, ev: StepThreeEvent) -> StopEvent:\n",
    "        # wait until we receive 3 events\n",
    "        result = ctx.collect_events(ev, [StepThreeEvent] * 3)\n",
    "        if result is None:\n",
    "            return None\n",
    "\n",
    "        # do something with all 3 results together\n",
    "        print('result:',result)\n",
    "        return StopEvent(result=\"Done\")\n",
    "\n",
    "async def main():\n",
    "    w = ConcurrentFlow(timeout=30, verbose=True)\n",
    "    await  w.run()\n",
    "\n",
    "    draw_all_possible_flows(ConcurrentFlow, filename=\"concurrent_workflow.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上过程是等待同类型的3个事件，其实也可以等待不同类型的事件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_a\n",
      "Doing something A-ish\n",
      "Step step_a produced event StepACompleteEvent\n",
      "Running step step_b\n",
      "Doing something B-ish\n",
      "Step step_b produced event StepBCompleteEvent\n",
      "Running step step_c\n",
      "Doing something C-ish\n",
      "Step step_c produced event StepCCompleteEvent\n",
      "Running step step_three\n",
      "Received event  Query 1\n",
      "Step step_three produced no event\n",
      "Running step step_three\n",
      "Received event  Query 2\n",
      "Step step_three produced no event\n",
      "Running step step_three\n",
      "Received event  Query 3\n",
      "Step step_three produced event StopEvent\n",
      "<class 'NoneType'>\n",
      "<class '__main__.StepAEvent'>\n",
      "<class '__main__.StepBEvent'>\n",
      "<class '__main__.StepCEvent'>\n",
      "<class '__main__.StepACompleteEvent'>\n",
      "<class '__main__.StepBCompleteEvent'>\n",
      "<class '__main__.StepCCompleteEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "concurrent2_workflow.html\n"
     ]
    }
   ],
   "source": [
    "class StepAEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepBEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepCEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepACompleteEvent(Event):\n",
    "    result: str\n",
    "\n",
    "class StepBCompleteEvent(Event):\n",
    "    result: str\n",
    "\n",
    "class StepCCompleteEvent(Event):\n",
    "    result: str\n",
    "\n",
    "class ConcurrentFlow2(Workflow):\n",
    "    @step\n",
    "    async def start(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> StepAEvent | StepBEvent | StepCEvent:\n",
    "        ctx.send_event(StepAEvent(query=\"Query 1\"))\n",
    "        ctx.send_event(StepBEvent(query=\"Query 2\"))\n",
    "        ctx.send_event(StepCEvent(query=\"Query 3\"))\n",
    "\n",
    "    @step\n",
    "    async def step_a(self, ctx: Context, ev: StepAEvent) -> StepACompleteEvent:\n",
    "        print(\"Doing something A-ish\")\n",
    "        return StepACompleteEvent(result=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_b(self, ctx: Context, ev: StepBEvent) -> StepBCompleteEvent:\n",
    "        print(\"Doing something B-ish\")\n",
    "        return StepBCompleteEvent(result=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_c(self, ctx: Context, ev: StepCEvent) -> StepCCompleteEvent:\n",
    "        print(\"Doing something C-ish\")\n",
    "        return StepCCompleteEvent(result=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_three(\n",
    "        self,\n",
    "        ctx: Context,\n",
    "        ev: StepACompleteEvent | StepBCompleteEvent | StepCCompleteEvent,\n",
    "    ) -> StopEvent:\n",
    "        print(\"Received event \", ev.result)\n",
    "\n",
    "        # wait until we receive 3 events\n",
    "        if (\n",
    "            ctx.collect_events(\n",
    "                ev,\n",
    "                [StepCCompleteEvent, StepACompleteEvent, StepBCompleteEvent],\n",
    "            )\n",
    "            is None\n",
    "        ):\n",
    "            return None\n",
    "\n",
    "        # do something with all 3 results together\n",
    "        return StopEvent(result=\"Done\")\n",
    "\n",
    "async def main():\n",
    "    w = ConcurrentFlow2(timeout=30, verbose=True)\n",
    "    await  w.run()\n",
    "\n",
    "    draw_all_possible_flows(ConcurrentFlow2, filename=\"concurrent2_workflow.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 继承自定义工作流类\n",
    "\n",
    "自定义工作流是继承WorkFlow类，其实自定义的工作流也是可以作为其他类的基类被继承，相当于实现了一个基础工作流，继承这个工作流再实现一个更加复杂的子类工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up\n",
      "Sending an email\n",
      "Finishing up\n",
      "Initial query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "\n",
    "class Step2Event(Event):\n",
    "    query: str\n",
    "\n",
    "class Step3Event(Event):\n",
    "    query: str\n",
    "\n",
    "class MainWorkflow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ev: StartEvent) -> Step2Event:\n",
    "        print(\"Starting up\")\n",
    "        return Step2Event(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ev: Step2Event) -> Step3Event:\n",
    "        print(\"Sending an email\")\n",
    "        return Step3Event(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ev: Step3Event) -> StopEvent:\n",
    "        print(\"Finishing up\")\n",
    "        return StopEvent(result=ev.query)\n",
    "\n",
    "w = MainWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run(query=\"Initial query\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up\n",
      "Sending an email\n",
      "Also sending a text message\n",
      "Finishing up\n",
      "Initial query\n"
     ]
    }
   ],
   "source": [
    "class Step2BEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class CustomWorkflow(MainWorkflow):\n",
    "    @step\n",
    "    async def step_two(self, ev: Step2Event) -> Step2BEvent:\n",
    "        print(\"Sending an email\")\n",
    "        return Step2BEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_two_b(self, ev: Step2BEvent) -> Step3Event:\n",
    "        print(\"Also sending a text message\")\n",
    "        return Step3Event(query=ev.query)\n",
    "    \n",
    "w = CustomWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run(query=\"Initial query\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌套工作流\n",
    "\n",
    "将某个工作流嵌入到已存在的工作流中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to run reflection\n",
      "Doing custom reflection\n",
      "Query is  Improved query\n",
      "Improved query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "\n",
    "class Step2Event(Event):\n",
    "    query: str\n",
    "\n",
    "\n",
    "class MainWorkflow(Workflow):\n",
    "    @step\n",
    "    async def start(\n",
    "        self, ctx: Context, ev: StartEvent, reflection_workflow: Workflow\n",
    "    ) -> Step2Event:\n",
    "        print(\"Need to run reflection\")\n",
    "        res = await reflection_workflow.run(query=ev.query)\n",
    "\n",
    "        return Step2Event(query=res)\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: Step2Event) -> StopEvent:\n",
    "        print(\"Query is \", ev.query)\n",
    "        # do something with the query here\n",
    "        return StopEvent(result=ev.query)\n",
    "\n",
    "class ReflectionFlow(Workflow):\n",
    "    @step\n",
    "    async def sub_start(self, ctx: Context, ev: StartEvent) -> StopEvent:\n",
    "        print(\"Doing custom reflection\")\n",
    "        return StopEvent(result=\"Improved query\")\n",
    "\n",
    "w = MainWorkflow(timeout=10, verbose=False)\n",
    "w.add_workflows(reflection_workflow=ReflectionFlow())\n",
    "result = await w.run(query=\"Initial query\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
